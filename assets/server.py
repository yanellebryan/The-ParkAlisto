# This script runs a Flask web server to provide real-time
# parking lot data and a video stream to a web front-end.
# NOW WITH BACKGROUND PROCESSING FOR FASTER PERFORMANCE!

import os
import time
import threading
from datetime import datetime
from collections import defaultdict, deque
import json
import cv2
import numpy as np
import torch
import easyocr
from flask import Flask, Response, jsonify, send_from_directory
from tkinter import Tk
from tkinter.filedialog import askopenfilename
import sys
import traceback
from queue import Queue

# Install Flask: pip install Flask
# Install EasyOCR: pip install easyocr
app = Flask(__name__)

# ==============================
# CONFIG
# ==============================
# Lot label (left big card)
LOT_NAME = "La Salle Parking Lot"

# Confirmation timers (seconds)
OCCUPANCY_CONFIRMATION_TIME = 10.0
VACANCY_CONFIRMATION_TIME = 10.0

# Performance settings
FRAME_SKIP_RATE = 10 # Process every 10th frame to speed up the loop
PROCESSING_WIDTH = 416 # Use a low-res square for faster inference
PROCESSING_HEIGHT = 416

# Background processing settings
NUM_PROCESSING_THREADS = 3  # Number of worker threads for plate/color detection

# Video source and mask files (will be set via file picker)
VIDEO_PATH = None
MASK_PATH = None
LOGO_PATH = None

# Create directories for storing plate screenshots
PLATE_SCREENSHOTS_DIR = "plate_screenshots"
if not os.path.exists(PLATE_SCREENSHOTS_DIR):
    os.makedirs(PLATE_SCREENSHOTS_DIR)

# Vehicle classes from COCO
VEHICLE_CLASSES = [2, 3, 5, 7]  # car, motorcycle, bus, truck
VEHICLE_NAMES = {2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'}

# ==============================
# Global State for Communication
# ==============================
# These global variables will be updated by the processing thread
# and read by the Flask server routes.
global_data = {
    'occupied': 0,
    'total': 0,
    'pending': 0,
    'last_update': 'N/A'
}
global_frame = None  # To hold the current processed frame for streaming

# Lock for safe access to global variables
frame_lock = threading.Lock()
data_lock = threading.Lock()

# Queue for background processing tasks
processing_queue = Queue()

# ==============================
# YOLOv5 model (COCO)
# ==============================
# This will download the weights if not already present.
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
model.conf = 0.25
model.iou = 0.45

# ==============================
# EasyOCR for license plate recognition
# ==============================
# This will download the models on first run
# Language codes: 'en' for English
plate_reader = easyocr.Reader(['en'])

# ==============================
# Background Processing Task Queue
# ==============================
class ProcessingTask:
    def __init__(self, spot_id, vehicle_roi, vehicle_type, timestamp):
        self.spot_id = spot_id
        self.vehicle_roi = vehicle_roi
        self.vehicle_type = vehicle_type
        self.timestamp = timestamp
        self.screenshot_filename = None

def background_processor_worker():
    """
    Worker thread that processes plate and color detection in the background.
    """
    print(f"[WORKER] Background processor thread started (ID: {threading.get_ident()})")
    
    while True:
        try:
            # Get task from queue (blocks until available)
            task = processing_queue.get()
            
            if task is None:  # Poison pill to stop thread
                print(f"[WORKER] Received stop signal")
                break
            
            print(f"[WORKER] Processing spot {task.spot_id} (queue size: {processing_queue.qsize()})")
            
            # Save screenshot first (fast operation)
            screenshot_filename = f"spot_{task.spot_id}_{int(time.time())}.jpg"
            screenshot_path = os.path.join(PLATE_SCREENSHOTS_DIR, screenshot_filename)
            try:
                cv2.imwrite(screenshot_path, task.vehicle_roi)
                task.screenshot_filename = screenshot_filename
                print(f"[WORKER] Saved screenshot: {screenshot_filename}")
            except Exception as e:
                print(f"[WORKER] Error saving screenshot: {e}")
            
            # Now do the slow operations
            start_time = time.time()
            
            # Detect plate number (SLOW - 2-5 seconds)
            plate_number = recognize_plate(task.vehicle_roi)
            plate_time = time.time() - start_time
            print(f"[WORKER] Plate detection took {plate_time:.2f}s: {plate_number}")
            
            # Detect color (MEDIUM - 0.5-1 second)
            color_start = time.time()
            color = get_vehicle_color(task.vehicle_roi)
            color_time = time.time() - color_start
            print(f"[WORKER] Color detection took {color_time:.2f}s: {color}")
            
            total_time = time.time() - start_time
            print(f"[WORKER] Total processing time: {total_time:.2f}s")
            
            # Update the parking log with results
            parking_log.update_processing_results(
                task.spot_id,
                plate_number,
                color,
                task.screenshot_filename
            )
            
            # Mark task as done
            processing_queue.task_done()
            
        except Exception as e:
            print(f"[WORKER] Error in background processor: {e}")
            traceback.print_exc()
            processing_queue.task_done()

# ==============================
# Parking History Log (UPDATED)
# ==============================
class ParkingLotLog:
    def __init__(self):
        # A deque to store log entries for a history display
        self.history = deque(maxlen=20)
        # A dictionary to track the current status of each spot
        self.active_log = {}
        # Lock for thread-safe updates
        self.log_lock = threading.Lock()

    def log_car_parked(self, spot_id, vehicle_type, vehicle_roi=None):
        """
        Logs a new car parking event with initial "Processing..." status.
        Creates a background task for plate/color detection.
        """
        timestamp = datetime.now().strftime("%I:%M:%S %p %B %d, %Y")
        
        with self.log_lock:
            log_entry = {
                'spot_id': spot_id,
                'plate_number': 'Processing...',
                'color': 'Processing...',
                'vehicle_type': vehicle_type,
                'timestamp_in': timestamp,
                'is_active': True,
                'plate_image': None,
                'processing_status': 'queued'
            }
            self.active_log[spot_id] = log_entry
            # Add a copy of the active entry to the history
            self.history.appendleft(log_entry.copy())
            print(f"LOG: Car ({vehicle_type}) parked at spot {spot_id}. Starting background processing...")
        
        # Queue background processing task (NON-BLOCKING)
        if vehicle_roi is not None:
            task = ProcessingTask(spot_id, vehicle_roi.copy(), vehicle_type, timestamp)
            processing_queue.put(task)
            print(f"LOG: Queued processing task for spot {spot_id} (queue size: {processing_queue.qsize()})")

    def update_processing_results(self, spot_id, plate_number, color, screenshot_filename):
        """
        Updates a log entry with the results from background processing.
        """
        with self.log_lock:
            if spot_id in self.active_log:
                log_entry = self.active_log[spot_id]
                log_entry['plate_number'] = plate_number
                log_entry['color'] = color
                log_entry['plate_image'] = screenshot_filename
                log_entry['processing_status'] = 'completed'
                
                # Update the history entry as well
                for entry in self.history:
                    if (entry['spot_id'] == spot_id and 
                        entry['timestamp_in'] == log_entry['timestamp_in'] and
                        entry['is_active']):
                        entry['plate_number'] = plate_number
                        entry['color'] = color
                        entry['plate_image'] = screenshot_filename
                        entry['processing_status'] = 'completed'
                        break
                
                print(f"LOG: Updated spot {spot_id} - Plate: {plate_number}, Color: {color}")
            else:
                print(f"LOG: Warning - spot {spot_id} not found in active log")

    def log_car_left(self, spot_id):
        """Updates a log entry when a car leaves."""
        with self.log_lock:
            if spot_id in self.active_log:
                log_entry = self.active_log[spot_id]
                log_entry['timestamp_out'] = datetime.now().strftime("%I:%M:%S %p %B %d, %Y")
                log_entry['is_active'] = False
                del self.active_log[spot_id]
                print(f"LOG: Car from spot {spot_id} has left.")

parking_log = ParkingLotLog()

# ==============================
# Utility Functions
# ==============================
def load_parking_mask(mask_path, width, height):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is None:
        raise ValueError(f"Mask image not found or invalid: {mask_path}")
    mask = cv2.resize(mask, (width, height))
    return mask

def get_parking_spots(mask):
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    parking_spots = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        parking_spots.append((x, y, w, h))
    parking_spots.sort(key=lambda spot: spot[0])  # left-to-right
    return parking_spots

def get_occupying_vehicle(spot_bbox, vehicles):
    """
    Checks if a parking spot is occupied and returns the vehicle info.
    Assumes all coordinates are in the same resolution.
    """
    spot_x, spot_y, spot_w, spot_h = spot_bbox
    spot_area = max(1, spot_w * spot_h)
    for vehicle in vehicles:
        veh_x1, veh_y1, veh_x2, veh_y2 = vehicle['bbox']
        
        inter_x1 = max(spot_x, veh_x1)
        inter_y1 = max(spot_y, veh_y1)
        inter_x2 = min(spot_x + spot_w, veh_x2)
        inter_y2 = min(spot_y + spot_h, veh_y2)
        
        if inter_x2 > inter_x1 and inter_y2 > inter_y1:
            intersection_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
            overlap_ratio = intersection_area / spot_area
            if overlap_ratio > 0.3:
                return vehicle
    return None

def get_vehicle_color(image_roi):
    """
    Analyzes the dominant color in a cropped image region.
    FIXED: Proper color detection with accurate color mapping.
    """
    if image_roi is None or image_roi.size == 0:
        return "N/A"
    
    try:
        # Resize for faster processing
        resized = cv2.resize(image_roi, (50, 50))
        pixels = resized.reshape(-1, 3).astype(np.float32)
        
        # Calculate dominant color using k-means clustering
        from sklearn.cluster import MiniBatchKMeans
        kmeans = MiniBatchKMeans(n_clusters=1, random_state=0, n_init=10).fit(pixels)
        dominant_bgr = kmeans.cluster_centers_[0].astype(int)
        dominant_bgr = tuple(map(int, dominant_bgr))
        
        print(f"[COLOR] Detected dominant BGR: {dominant_bgr}")
        
        # Enhanced color mapping with more realistic thresholds
        colors = {
            'white': (240, 240, 240),
            'black': (30, 30, 30),
            'gray': (128, 128, 128),
            'silver': (192, 192, 192),
            'red': (50, 50, 180),
            'dark red': (30, 30, 120),
            'green': (50, 150, 50),
            'dark green': (30, 90, 30),
            'blue': (180, 100, 50),
            'dark blue': (120, 60, 30),
            'yellow': (50, 200, 200),
            'cyan': (200, 200, 50),
            'magenta': (180, 50, 180),
            'orange': (50, 140, 220),
            'brown': (42, 42, 120),
            'beige': (150, 180, 200)
        }
        
        # Find the closest color using Euclidean distance
        min_dist = float('inf')
        closest_color_name = "unknown"
        
        for name, bgr in colors.items():
            dist = np.sqrt(sum((a - b) ** 2 for a, b in zip(dominant_bgr, bgr)))
            if dist < min_dist:
                min_dist = dist
                closest_color_name = name
        
        print(f"[COLOR] Closest match: {closest_color_name} (distance: {min_dist:.2f})")
        return closest_color_name
        
    except Exception as e:
        print(f"[COLOR] Detection error: {e}")
        traceback.print_exc()
        return "N/A"

def preprocess_for_ocr(image):
    """
    Enhanced preprocessing for better OCR results on license plates.
    """
    if image is None or image.size == 0:
        return None
    
    # Convert to grayscale
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # Resize to improve OCR accuracy - make it much larger
    h, w = gray.shape
    # Scale up significantly for better character recognition
    scale_factor = max(3.0, 80/h, 300/w)  # Ensure minimum size
    new_h = int(h * scale_factor)
    new_w = int(w * scale_factor)
    resized = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    
    # Apply multiple preprocessing approaches and return the best one
    processed_versions = []
    
    # Version 1: Simple threshold
    _, thresh1 = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    processed_versions.append(thresh1)
    
    # Version 2: Adaptive threshold
    adaptive = cv2.adaptiveThreshold(
        resized, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 
        max(3, int(new_h/10)), 2
    )
    processed_versions.append(adaptive)
    
    # Version 3: Enhanced contrast then threshold
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(resized)
    _, thresh2 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    processed_versions.append(thresh2)
    
    # Version 4: Morphological operations
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
    morph = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)
    processed_versions.append(morph)
    
    # Return the version with best contrast
    best_version = processed_versions[0]
    best_score = 0
    
    for version in processed_versions:
        hist = cv2.calcHist([version], [0], None, [256], [0, 256])
        black_pixels = hist[0]
        white_pixels = hist[255] 
        total_pixels = version.shape[0] * version.shape[1]
        
        if total_pixels > 0:
            black_ratio = black_pixels / total_pixels
            white_ratio = white_pixels / total_pixels
            score = min(black_ratio, white_ratio) * (1 - abs(black_ratio - white_ratio))
            if score > best_score:
                best_score = score
                best_version = version
    
    return best_version

def find_plate_regions(image_roi):
    """
    Try to find rectangular regions that might contain license plates.
    """
    if image_roi is None or image_roi.size == 0:
        return [image_roi]
    
    # Convert to grayscale if needed
    if len(image_roi.shape) == 3:
        gray = cv2.cvtColor(image_roi, cv2.COLOR_BGR2GRAY)
    else:
        gray = image_roi.copy()
    
    # Apply edge detection
    edges = cv2.Canny(gray, 50, 150)
    
    # Find contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    plate_candidates = []
    h, w = gray.shape
    
    for contour in contours:
        x, y, rect_w, rect_h = cv2.boundingRect(contour)
        
        aspect_ratio = rect_w / rect_h if rect_h > 0 else 0
        area_ratio = (rect_w * rect_h) / (w * h)
        
        if (2.0 <= aspect_ratio <= 5.0 and 
            0.02 <= area_ratio <= 0.3 and 
            rect_w >= 30 and rect_h >= 10):
            
            pad_x = max(5, int(rect_w * 0.1))
            pad_y = max(3, int(rect_h * 0.1))
            
            x1 = max(0, x - pad_x)
            y1 = max(0, y - pad_y)
            x2 = min(w, x + rect_w + pad_x)
            y2 = min(h, y + rect_h + pad_y)
            
            plate_region = image_roi[y1:y2, x1:x2]
            if plate_region.size > 0:
                plate_candidates.append(plate_region)
    
    if not plate_candidates:
        bottom_portion = image_roi[int(h*0.7):h, :]
        if bottom_portion.size > 0:
            plate_candidates.append(bottom_portion)
        else:
            plate_candidates.append(image_roi)
    
    return plate_candidates

def is_valid_plate_text(text):
    """
    Enhanced validation for license plate text.
    """
    if not text or len(text) < 2:
        return False
    
    cleaned = text.replace(' ', '').replace('-', '').replace('_', '').upper()
    cleaned = ''.join(c for c in cleaned if c.isalnum())
    
    if len(cleaned) < 3 or len(cleaned) > 10:
        return False
    
    has_letter = any(c.isalpha() for c in cleaned)
    has_number = any(c.isdigit() for c in cleaned)
    
    letter_count = sum(1 for c in cleaned if c.isalpha())
    number_count = sum(1 for c in cleaned if c.isdigit())
    
    if has_letter and has_number:
        return True
    elif letter_count >= 3 and number_count <= 2:
        return True
    elif number_count >= 3 and letter_count <= 2:
        return True
    
    return False

def recognize_plate(image_roi):
    """
    Enhanced license plate recognition with better preprocessing and multiple attempts.
    """
    if image_roi is None or image_roi.size == 0:
        return "N/A"
    
    try:
        print(f"[OCR] Starting plate recognition...")
        plate_regions = find_plate_regions(image_roi)
        
        best_result = ""
        best_confidence = 0.0
        
        for idx, region in enumerate(plate_regions):
            print(f"[OCR] Processing region {idx+1}/{len(plate_regions)}")
            
            ocr_configs = [
                {'width_ths': 0.4, 'height_ths': 0.4, 'paragraph': True, 'decoder': 'greedy'},
                {'width_ths': 0.3, 'height_ths': 0.3, 'paragraph': False, 'decoder': 'greedy'},
                {'width_ths': 0.1, 'height_ths': 0.1, 'paragraph': True, 'decoder': 'beamsearch'}
            ]
            
            for config_idx, config in enumerate(ocr_configs):
                try:
                    results = plate_reader.readtext(
                        region, 
                        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 -',
                        **config
                    )
                    
                    full_text = ""
                    total_confidence = 0.0
                    valid_detections = 0
                    
                    results.sort(key=lambda x: x[0][0][0] if len(x[0]) > 0 else 0)
                    
                    for (bbox, text, confidence) in results:
                        cleaned_text = text.strip().upper()
                        if len(cleaned_text) > 0 and confidence > 0.2:
                            full_text += cleaned_text
                            total_confidence += confidence
                            valid_detections += 1
                    
                    if valid_detections > 0:
                        avg_confidence = total_confidence / valid_detections
                        full_text_cleaned = full_text.replace(' ', '').replace('-', '')
                        
                        if avg_confidence > best_confidence and is_valid_plate_text(full_text_cleaned):
                            best_result = full_text_cleaned
                            best_confidence = avg_confidence
                            print(f"[OCR] Found: '{best_result}' (confidence: {best_confidence:.2f})")
                            
                except Exception as e:
                    print(f"[OCR] Error with config {config_idx}: {e}")
                    continue
            
            # Try preprocessed version
            try:
                preprocessed = preprocess_for_ocr(region)
                if preprocessed is not None:
                    for config in ocr_configs:
                        try:
                            results = plate_reader.readtext(
                                preprocessed,
                                allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 -',
                                **config
                            )
                            
                            full_text = ""
                            total_confidence = 0.0
                            valid_detections = 0
                            
                            results.sort(key=lambda x: x[0][0][0] if len(x[0]) > 0 else 0)
                            
                            for (bbox, text, confidence) in results:
                                cleaned_text = text.strip().upper()
                                if len(cleaned_text) > 0 and confidence > 0.2:
                                    full_text += cleaned_text
                                    total_confidence += confidence
                                    valid_detections += 1
                            
                            if valid_detections > 0:
                                avg_confidence = total_confidence / valid_detections
                                full_text_cleaned = full_text.replace(' ', '').replace('-', '')
                                
                                if avg_confidence > best_confidence and is_valid_plate_text(full_text_cleaned):
                                    best_result = full_text_cleaned
                                    best_confidence = avg_confidence
                                    print(f"[OCR] Found (preprocessed): '{best_result}' (confidence: {best_confidence:.2f})")
                                    
                        except Exception as e:
                            continue
                            
            except Exception as e:
                print(f"[OCR] Preprocessing error: {e}")
        
        if best_confidence > 0.2 and best_result:
            print(f"[OCR] Final result: {best_result}")
            return best_result
        
        print(f"[OCR] No valid plate detected")
        return "N/A"
        
    except Exception as e:
        print(f"[OCR] Recognition error: {e}")
        return "N/A"

# ==============================
# Parking Spot Tracker
# ==============================
class ParkingSpotTracker:
    def __init__(self, spot_id, confirmation_time_occupied=30.0, confirmation_time_vacant=30.0):
        self.spot_id = spot_id
        self.is_occupied = False
        self.pending_status = None
        self.status_change_start = None
        self.confirmation_time_occupied = confirmation_time_occupied
        self.confirmation_time_vacant = confirmation_time_vacant
        self.last_detection_time = None
        self.confirmed_vehicle_info = None
        self.current_vehicle_roi = None

    def update(self, detected_occupied, current_time, vehicle_info=None):
        if detected_occupied and vehicle_info:
            self.current_vehicle_roi = vehicle_info.get('image_roi')
        elif not detected_occupied:
            self.current_vehicle_roi = None
            
        if detected_occupied == self.is_occupied:
            self.pending_status = None
            self.status_change_start = None
            self.last_detection_time = current_time
            return self.is_occupied, None
        
        if self.pending_status != detected_occupied:
            self.pending_status = detected_occupied
            self.status_change_start = current_time
            self.last_detection_time = current_time
            if detected_occupied:
                self.confirmed_vehicle_info = vehicle_info
            return self.is_occupied, None
        
        self.last_detection_time = current_time
        confirmation_time = self.confirmation_time_occupied if detected_occupied else self.confirmation_time_vacant
        time_elapsed = current_time - self.status_change_start
        
        if time_elapsed >= confirmation_time:
            was_occupied = self.is_occupied
            self.is_occupied = detected_occupied
            self.pending_status = None
            self.status_change_start = None

            if self.is_occupied and not was_occupied:
                return self.is_occupied, self.confirmed_vehicle_info
            elif not self.is_occupied and was_occupied:
                return self.is_occupied, self.spot_id

        return self.is_occupied, None

    def get_status_info(self, current_time):
        info = {
            'is_occupied': self.is_occupied,
            'pending_status': self.pending_status,
            'time_to_change': None,
            'is_pending': False
        }
        if self.pending_status is not None and self.status_change_start is not None:
            confirmation_time = self.confirmation_time_occupied if self.pending_status else self.confirmation_time_vacant
            time_elapsed = current_time - self.status_change_start
            time_remaining = max(0, confirmation_time - time_elapsed)
            info['time_to_change'] = time_remaining
            info['is_pending'] = True
        return info

# ==============================
# Main Processing Loop (OPTIMIZED)
# ==============================
def process_video_loop():
    global global_frame, global_data, VIDEO_PATH, MASK_PATH

    try:
        cap = cv2.VideoCapture(VIDEO_PATH)
        if not cap.isOpened():
            print(f"Error: Could not open input video: {VIDEO_PATH}", file=sys.stderr)
            return

        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)

        mask = load_parking_mask(MASK_PATH, width, height)
        parking_spots = get_parking_spots(mask)
        total_spots = len(parking_spots)
        
        print(f"Found {total_spots} parking spots")

        spot_trackers = {
            i: ParkingSpotTracker(i + 1, OCCUPANCY_CONFIRMATION_TIME, VACANCY_CONFIRMATION_TIME)
            for i, _ in enumerate(parking_spots)
        }

        start_time = time.time()
        frame_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                continue

            frame_count += 1
            if frame_count % FRAME_SKIP_RATE != 0:
                continue

            current_time = time.time() - start_time
            loop_start = time.time()
            
            # YOLO detection (FAST)
            processed_frame = cv2.resize(frame, (PROCESSING_WIDTH, PROCESSING_HEIGHT))
            results = model(processed_frame)
            
            vehicle_info_list = []
            try:
                det = results.pandas().xyxy[0]
                scale_x = width / PROCESSING_WIDTH
                scale_y = height / PROCESSING_HEIGHT

                for _, d in det.iterrows():
                    if int(d['class']) in VEHICLE_CLASSES:
                        x1 = int(float(d['xmin']) * scale_x)
                        y1 = int(float(d['ymin']) * scale_y)
                        x2 = int(float(d['xmax']) * scale_x)
                        y2 = int(float(d['ymax']) * scale_y)
                        
                        vehicle_roi = frame[y1:y2, x1:x2]
                        
                        vehicle_info_list.append({
                            'bbox': (x1, y1, x2, y2),
                            'type': VEHICLE_NAMES.get(int(d['class']), 'vehicle'),
                            'confidence': float(d['confidence']),
                            'image_roi': vehicle_roi
                        })
            except Exception as e:
                print(f"YOLO detection error: {e}")
                pass

            # Draw annotations (FAST)
            annotated_frame = frame.copy()
            for veh in vehicle_info_list:
                x1, y1, x2, y2 = veh['bbox']
                label = f"{veh['type']}: {veh['confidence']:.2f}"
                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
                cv2.putText(annotated_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

            # Update spots and draw on frame (FAST - no OCR here!)
            occupied_count, pending_changes = 0, 0
            for i, spot in enumerate(parking_spots):
                occupying_vehicle = get_occupying_vehicle(spot, vehicle_info_list)
                detected_occupied = occupying_vehicle is not None
                tracker = spot_trackers[i]
                
                # Update tracker and get confirmation data
                confirmed_occupied, info = tracker.update(detected_occupied, current_time, occupying_vehicle)

                # Check for confirmed status changes and log them
                if info is not None:
                    if confirmed_occupied:  # A car has just parked
                        # Just log it immediately, background thread will process
                        parking_log.log_car_parked(tracker.spot_id, info['type'], info['image_roi'])
                    else:  # A car has just left
                        parking_log.log_car_left(info)

                if confirmed_occupied:
                    occupied_count += 1
                if tracker.get_status_info(current_time)['is_pending']:
                    pending_changes += 1

                x, y, w, h = spot
                color = (0, 0, 255) if confirmed_occupied else (0, 255, 0)
                cv2.rectangle(annotated_frame, (x, y), (x+w, y+h), color, 2)
                cv2.putText(annotated_frame, f"P{i+1}", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # Update global data
            with data_lock:
                global_data['occupied'] = occupied_count
                global_data['total'] = total_spots
                global_data['pending'] = pending_changes
                global_data['last_update'] = datetime.now().strftime("%I:%M:%S %p")
                global_data['queue_size'] = processing_queue.qsize()  # Show queue status
            
            loop_time = time.time() - loop_start
            print(f"[MAIN] Frame processed in {loop_time:.3f}s | Occupied={occupied_count}/{total_spots} | Queue={processing_queue.qsize()}")

            # Update frame for streaming
            with frame_lock:
                global_frame = annotated_frame.copy()

            time.sleep(1/fps if fps > 0 else 0.03)

        cap.release()
    except Exception as e:
        print(f"An error occurred in the video processing thread: {e}", file=sys.stderr)
        traceback.print_exc(file=sys.stderr)

# ==============================
# Flask API Endpoints
# ==============================
@app.route('/')
def index():
    """Serves the main dashboard HTML page."""
    return send_from_directory('.', 'index.html')

@app.route('/data')
def get_data():
    """Returns the latest parking status data as a JSON object."""
    with data_lock:
        return jsonify(global_data)

@app.route('/parking_history')
def get_history():
    """Returns the parking history log as a JSON object."""
    with data_lock:
        return jsonify(list(parking_log.history))

@app.route('/plate_screenshots/<filename>')
def serve_plate_screenshot(filename):
    """Serves plate screenshot images."""
    return send_from_directory(PLATE_SCREENSHOTS_DIR, filename)

def generate_frames():
    """Generates JPEG frames for the video stream."""
    while True:
        with frame_lock:
            if global_frame is None:
                time.sleep(0.1)
                continue
            try:
                ret, buffer = cv2.imencode('.jpg', global_frame)
                if not ret:
                    time.sleep(0.1)
                    continue
                frame_bytes = buffer.tobytes()
            except Exception as e:
                print(f"Frame encoding error: {e}")
                time.sleep(0.1)
                continue
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        time.sleep(0.05)

@app.route('/video_feed')
def video_feed():
    """Serves the real-time video stream as an MJPEG stream."""
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

# Enable CORS for development
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE')
    return response

# ==============================
# Entry Point
# ==============================
def main():
    print("=== ParkAlisto: Dashboard Server ===")
    print("üöÄ NOW WITH BACKGROUND PROCESSING!")
    
    root = Tk()
    root.withdraw()
    global VIDEO_PATH, MASK_PATH, LOGO_PATH
    
    VIDEO_PATH = askopenfilename(title="Select a Video File", filetypes=[("Video Files", "*.mp4 *.avi *.mov"), ("All Files", "*.*")])
    if not VIDEO_PATH:
        print("Video selection is required. Exiting.", file=sys.stderr)
        return

    MASK_PATH = askopenfilename(title="Select the Mask Image (white boxes on black background)", filetypes=[("Image Files", "*.png *.jpg *.jpeg"), ("All Files", "*.*")])
    if not MASK_PATH:
        print("Mask selection is required. Exiting.", file=sys.stderr)
        return

    print(f"Selected video: {VIDEO_PATH}")
    print(f"Selected mask: {MASK_PATH}")
    
    # Start background processing worker threads
    print(f"\nüîß Starting {NUM_PROCESSING_THREADS} background processing threads...")
    worker_threads = []
    for i in range(NUM_PROCESSING_THREADS):
        worker = threading.Thread(target=background_processor_worker, name=f"Worker-{i+1}")
        worker.daemon = True
        worker.start()
        worker_threads.append(worker)
        print(f"   ‚úì Worker thread {i+1} started")

    # Start main video processing thread
    print("\nüé• Starting main video processing thread...")
    processing_thread = threading.Thread(target=process_video_loop, name="VideoProcessor")
    processing_thread.daemon = True
    processing_thread.start()

    print("Waiting for video processing to start...")
    while global_frame is None:
        print(".", end="", flush=True)
        time.sleep(1)
    print(" Ready!")

    print("\n" + "="*60)
    print("üöÄ SERVER IS RUNNING WITH BACKGROUND PROCESSING!")
    print("="*60)
    print("üìç Dashboard: http://localhost:5000")
    print("üé• Video feed: http://localhost:5000/video_feed")
    print("üìä Data API: http://localhost:5000/data")
    print("üìù History API: http://localhost:5000/parking_history")
    print("üñºÔ∏è  Screenshots: http://localhost:5000/plate_screenshots/<filename>")
    print("="*60)
    print("\n‚ú® HOW IT WORKS:")
    print("   1. Car detected ‚Üí Immediately logged with 'Processing...'")
    print("   2. Screenshot saved instantly")
    print("   3. Background threads process plate & color (2-5 seconds)")
    print("   4. Results update in real-time when ready")
    print("   5. Video stream stays smooth and fast!")
    print("\n‚ö° PERFORMANCE BOOST:")
    print(f"   ‚Ä¢ {NUM_PROCESSING_THREADS} parallel worker threads")
    print("   ‚Ä¢ Main video loop is NON-BLOCKING")
    print("   ‚Ä¢ ~10x faster real-time detection")
    print("="*60 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=False)


    

if __name__ == "__main__":
    main()



